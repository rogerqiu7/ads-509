{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/roger.qiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/roger.qiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK resources if they haven't been downloaded before\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Connection at 0x7fc133a9d030>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fc1339e0500>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables in the database: [('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "# Query to list all tables in the SQLite database\n",
    "tables_query = convention_cur.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    ")\n",
    "\n",
    "# Fetch all results\n",
    "tables = tables_query.fetchall()\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"Available tables in the database:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fc1339e0500>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from', 'does', 'are', 'were', 'that']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "list(stop_words)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. As part of your cleaning process,\n",
    "# remove the stopwords from the text. The second element of the sublist\n",
    "# should be the party. \n",
    "\n",
    "for row in query_results:\n",
    "\n",
    "    # join characters into 1 string, only get first row to exclude the party\n",
    "    raw_text = ''.join(char for char in row[0])\n",
    "\n",
    "    # loop through raw text and lowercase, do not include any puncuations\n",
    "    cleaned_text = ''.join(char.lower() for char in raw_text if char not in string.punctuation)\n",
    "\n",
    "    # convert the cleaned text into tokens\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    \n",
    "    # only keep tokens if they are not a stopword as filtered tokens\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # join tokens back into a single string with spaces\n",
    "    final_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    # finally, append the cleaned data and the party to convention_data\n",
    "    convention_data.append([final_text, row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['skip content company careers press freelancers blog Ã— services transcription captions foreign subtitles translation freelancers contact login Â« return transcript library home transcript categories transcripts 2020 election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug 21 2020 2020 democratic national convention dnc night 4 transcript rev â€º blog â€º transcripts â€º 2020 election transcripts â€º 2020 democratic national convention dnc night 4 transcript night 4 2020 democratic national convention dnc august 20 read full transcript event transcribe content try rev free save time transcribing captioning subtitling',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['paycheck protection program mean company coronavirus struck', 'Republican'],\n",
       " ['joe bring us together end pandemic make sure prepared next one joe bring us together squarely face dismantle racial injustice furthering work generations joe believe build beloved community one strong decent kind one see â€™ vision parents grandparents fought',\n",
       "  'Democratic'],\n",
       " ['left â€™ backward view see america free exceptional nation earth instead see wicked nation must punished sins opponents say redemption come giving power tired anthem spoken every repressive movement throughout history country â€™ look career politicians salvation america â€™ turn government restore souls put faith almighty god joe biden savior america â€™ soul destroyer america â€™ jobs given chance destroyer american greatness 47 years joe biden took donations blue collar workers gave hugs even kisses told felt pain flew back washington voted ship jobs china many distant lands joe biden spent entire career outsourcing dreams dreams american workers offshoring jobs opening borders sending sons daughters fight endless foreign wars wars never ended four years ago ran president could watch betrayal country longer could sit career politicians let countries take advantage us trade borders foreign policy national defense nato partners example far behind defense payments strong urging agreed pay 130 billion year first time 20 years upped payments 130 billion ultimately go 400 billion year secretary general stoltenberg heads nato amazed watching many years said president trump one else able thank moment left former life behind good life done nothing fight political establishment never expected could never forgive breaking cardinal rule washington politics kept promise together ended rule failed political class desperate get power back means necessary â€™ seen angry instead putting first simply said â€ america first â€ donald trump 021108 thank days taking office shocked washington establishment withdrew last administration â€™ jobkilling transpacific partnership immediately approved keystone xl dakota access pipelines unfair costly paris climate accord secured first time american energy independence passed record setting tax regulation cuts rate nobody ever seen within three short years built strongest economy history world washington insiders asked stand china pleaded let china continue stealing jobs ripping us robbing country blind kept word american people took toughest boldest strongest hardest hitting action china american history far',\n",
       "  'Republican'],\n",
       " ['â€™ close family â€™ oldest five girls', 'Democratic'],\n",
       " ['seek nation rises together falls apart anarchy anger know way overcome america â€™ challenges embrace america â€™ strengths striving reach brighter future every child goes world class school chosen parents every family lives safe community good jobs every entrepreneur freedom achieve inspire every believer worship without fear every life protected every girl boy every woman man every race religion best shot best life election must choose candidate continue delivering vision president trump vice president pence support america promise build progress past unlock promise future future starts american people reelect president donald trump thank goodnight may god always bless america donald trump jr 022404 good evening america â€™ donald trump jr â€™ tonight talk great american story talk country love land promise opportunity heroes greatness short months ago seeing american dream become reality citizens ever greatest prolonged economic expansion american history lowest unemployment rate nearly 50 years lowest unemployment rates ever black americans hispanic americans women pretty much every demographic group courtesy chinese communist party virus struck president quickly took action shut travel china joe biden democrat allies called father racist xenophobe put political correctness ahead safety security american people donald trump jr 022503 fortunately virus began spread president acted quickly insured ventilators got hospitals needed delivered pp e brave frontline workers rallied mighty american private sector tackle new challenge â€™ work light end tunnel job gains outpacing called experts expected biden â€™ radical left wing policies would stop economic recovery cold â€™ already talking shutting country â€™ madness democrats claim workers â€™ spent entire pandemic trying sneak tax break millionaires democrat states covid relief bill attacked father suspending payroll tax middle class workers fact think joe biden â€™ entire economic platform seems designed crush working men women donald trump jr 022603 supported worst trade deals history planet voted nafta nightmare tubes went auto industry pushed tpp goodbye manufacturing jobs beijing biden weak china intelligence community recently assessed chinese communist party favors biden know â€™ weaken us economically world stage biden also wants bring illegal immigrants take jobs american citizens open border policies would drive wages americans time low income workers getting real wage increases first time modern history â€™ pledged repeal trump tax cuts biggest country eight years obama biden â€™ slow growth trump â€™ policies like rocket fuel economy especially middle class biden promised take money back pocket keep swamp makes sense though considering joe biden basically loch ness monster swamp donald trump jr 022714 past half century â€™ lurking around sticks head every run president disappears â€™ much â€™ looking hope look man failed obama biden administration never could built greatest economy country ever seen president trump stronger ever put mind obstacle america â€™ surmount except â€™ difference time past parties believed goodness america agreed wanted go disagreed get time party attacking principles nation founded freedom thought freedom speech freedom religion rule law thomas jefferson famously said â€œ sworn upon altar god eternal hostility every form tyranny mind man â€ founders believed nothing important protecting god given right think donald trump jr 022829 left â€™ trying cancel founders â€™ seem understand important principle order improve future must learn past erase â€™ going tear monuments forget people built great nation instead learn past â€™ repeat mistakes work tirelessly improve lives americans joe biden radical left coming freedom speech want bully us submission get way longer silent majority silenced majority stop freedom expression used liberal value least radical left took republican party home free speech place anyone background speak mind may best ideas win donald trump jr 022931 people faith attack â€™ allowed go church mass chaos streets gets pass â€™ almost like election shaping church work school versus rioting looting vandalism words biden democrats peaceful protesting anarchists flooding streets democrat mayors ordering police stand small businesses across america many minority owned torched mobs democrat mayors pretend â€™ happening actually called summer love donald trump jr 023013 brings another important principle every american must free live without fear violence country communities homes men women created equal must treated equally law â€™ must put end racism must ensure police officer abuses powers held accountable happened george floyd disgrace know police officer know agree lose sight fact police american heroes deserve deepest appreciation matter democrats say know dial 911 â€™ want going voicemail defunding police option everything starts safety security â€™ anything else without donald trump jr 023111 â€™ focus building better future children without peace mind study safely classrooms play safely neighborhoods sleep safely beds safety beginning trump â€™ america land opportunity place promise fortunate enough grow family could afford best schools finest universities great education exclusive right rich powerful must accessible â€™ dad pro school choice â€™ â€™ called education access civil rights issue time time unacceptable many african american hispanic american children stuck bad schools zip code donald trump stand democrats really wanted help minorities underserved communities instead bowing big money union bosses â€™ let parents choose school best kids donald trump jr 023217 â€™ limit immigration protect american workers â€™ support police protect neighborhoods â€™ learn negotiate trade deals prioritize america â€™ interest change â€™ end endless wars quit sending young people solve problems foreign lands â€™ cut taxes families workers â€™ create opportunity zones drive investment inner cities words democrats cared forgotten men women country â€™ exactly president trump america greatest country earth father â€™ entire worldview revolves around idea always even better imagine life want one great job beautiful home perfect family imagine country want live one true equal opportunity hard work pays justice serve compassion without partiality donald trump jr 023326 imagine world evils communism radical islamic terrorism given chance spread heroes celebrated good guys win life country world donald trump republican party yes unlike joe biden radical left democrats party open everyone starts rejecting radicals want drag us dark embracing man represents bright beautiful future starts reelecting donald j trump president united states thank god bless america',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2332 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnc', 'kind', 'remind', 'continues', 'resolve']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_words)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    # split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # return the word and true as a dictionary, only if that word is a feature word\n",
    "    ret_dict = {word: True for word in set(words) if word in fw}\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if feature words is not empty\n",
    "assert(len(feature_words)>0)\n",
    "\n",
    "# checks conv features function when the following input is given, returns certain words as keys\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'blog': True,\n",
       "   'election': True,\n",
       "   'skip': True,\n",
       "   'trump': True,\n",
       "   'Ã—': True,\n",
       "   'august': True,\n",
       "   'full': True,\n",
       "   'categories': True,\n",
       "   'company': True,\n",
       "   'subtitling': True,\n",
       "   'political': True,\n",
       "   'event': True,\n",
       "   'captioning': True,\n",
       "   'library': True,\n",
       "   '2020': True,\n",
       "   'debate': True,\n",
       "   'aug': True,\n",
       "   'contact': True,\n",
       "   'time': True,\n",
       "   'content': True,\n",
       "   'transcribing': True,\n",
       "   'translation': True,\n",
       "   'transcripts': True,\n",
       "   'testimony': True,\n",
       "   'entertainment': True,\n",
       "   'sports': True,\n",
       "   'freelancers': True,\n",
       "   'interview': True,\n",
       "   'free': True,\n",
       "   'foreign': True,\n",
       "   'transcribe': True,\n",
       "   'try': True,\n",
       "   'hearing': True,\n",
       "   'transcription': True,\n",
       "   'classic': True,\n",
       "   'democratic': True,\n",
       "   'night': True,\n",
       "   'â€º': True,\n",
       "   'return': True,\n",
       "   'save': True,\n",
       "   'subtitles': True,\n",
       "   'login': True,\n",
       "   'national': True,\n",
       "   'dnc': True,\n",
       "   '20': True,\n",
       "   'rev': True,\n",
       "   'transcript': True,\n",
       "   'convention': True,\n",
       "   'read': True,\n",
       "   'speech': True,\n",
       "   'press': True,\n",
       "   'conference': True,\n",
       "   'services': True,\n",
       "   'careers': True,\n",
       "   'donald': True,\n",
       "   'congressional': True,\n",
       "   'technology': True,\n",
       "   'home': True,\n",
       "   '4': True,\n",
       "   'Â«': True,\n",
       "   'captions': True,\n",
       "   'financial': True},\n",
       "  'Democratic')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]\n",
    "\n",
    "featuresets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.1 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.8 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "There are a few interesting observations from this first naive bayes models and its most informative features. The model only has an accuracy of 50%, I'm curious to see why it performed so poorly and how future models will compare to it. As for the most important features, the results are very interesting. China appears to be the most important word for deciding parties, as well as votes and enforcement. Because China is a deciding feature for republicans, it must mean that the party brings it up much more than democrats. A big reason for this could be that the republicans in the convention have less favorable views of the US relationship and trade deals with China than comapred to democrats and therefore, bring it up much more. The most important democrat terms here appear to be votes and climate. I find it interesting that democrats bring up the term votes so much more than republicans, although the climate term makes sense. Finally, the vast majority of the important features are deciding for the republican party, my thoughts on this is that republicans in this convention tend to use the same key words much more frequently than democrats do and that democrats use a much larger variety of terms so their terms have less feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['brooks joins alabama delegation voting flawed funding bill httptco3cwjiwysnq',\n",
       "  'Mo Brooks',\n",
       "  'Republican'],\n",
       " ['brooks senate democrats allowing president give americans â€™ jobs illegals securetheborder httpstcomzteax8xs6',\n",
       "  'Mo Brooks',\n",
       "  'Republican'],\n",
       " ['nasa square event sat 11am â€“ 4pm stop amp hear incredible work done al05 downtownhsv httptcor9zy8wmepa',\n",
       "  'Mo Brooks',\n",
       "  'Republican'],\n",
       " ['trouble socialism eventually run peoples money margaret thatcher httpstcox97g7wzqwj',\n",
       "  'Mo Brooks',\n",
       "  'Republican'],\n",
       " ['trouble socialism eventually run peoples money â€“ thatcher shell sorely missed httptcoz8gbndquh8',\n",
       "  'Mo Brooks',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for candidate, party, tweet in results:\n",
    "\n",
    "    # decode to string format first, else run into error\n",
    "    tweet = tweet.decode('utf-8')\n",
    "\n",
    "    # join characters together\n",
    "    raw_text = ''.join(char for char in tweet)\n",
    "    \n",
    "    # loop through raw text and lowercase, do not include any puncuations\n",
    "    cleaned_text = ''.join(char.lower() for char in raw_text if char not in string.punctuation)\n",
    "    \n",
    "    # convert the cleaned text into tokens\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    \n",
    "    # only keep tokens if they are not a stopword as filtered tokens\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # join tokens back into a single string with spaces\n",
    "    final_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    # append the cleaned, tokenized text and the candidate's party to tweet_data\n",
    "    tweet_data.append([final_text, candidate, party])\n",
    "\n",
    "tweet_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "\n",
    "len(tweet_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: â€™ grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let â€™ make even greater kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot â€™ 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus â€™ plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla â€™ 22 years eastside commitment amp saluted community leaders last night â€™ awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, candidate, party in tweet_data_sample :\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "\n",
    "    # convert tweets to features using the conv_features function and feature words defined earlier\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # use the model from earlier to classify the tweet\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 0}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 0})})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, candidate, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    \n",
    "    # convert tweets to features using the conv_features function and feature words defined earlier\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # use the model from earlier to classify the tweet\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3731, 'Democratic': 547}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4841, 'Democratic': 883})})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The classifier seems to have a bias toward labeling tweets as republican given that tweets from both parties are more frequently labeled as such. This could either be caused by an imbalance in the sample training data or a set of feature words are given more importance to to Republicans label regardless of the actual party.\n",
    "\n",
    "For the results, of the total Republican tweets classified, 4291, about 86% are correctly labeled as Republican, and only 14% are misclassified as democrat, which is not bad. The issue, thought is the classification of democrat tweets, where out of the total 5711, only about 15% are correctly classified as Democratic, and a vast majority, 85% are misclassified as republican. Based on this, next steps could be to assess the training data, the models feature importance and make necesarry updates to improve the overall prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
